{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc470f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/student_directories/AuFa/venv310/lib64/python3.10/site-packages/opensmile/core/smile.py:252: UserWarning: Feature set 'FeatureSet.eGeMAPS' is deprecated, consider switching to 'FeatureSet.eGeMAPSv02'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Training Set ---\n",
      "\n",
      "Processing directory: /mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/student_directories/AuFa/bonafide_audio_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting from bonafide_audio_train:  22%|██▏       | 579/2580 [01:26<04:21,  7.65it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.fftpack import dct\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import opensmile\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "\n",
    "# --- Paths ---\n",
    "TEAMMATE_DATA_PATH = '/mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/student_directories/AuFa/'\n",
    "OUTPUT_DIR = os.path.join(TEAMMATE_DATA_PATH, \"processed_data_aligned_lld\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "TEMP_AUDIO_PATH = os.path.join(OUTPUT_DIR, \"temp_5s_audio.wav\") # For temporary audio clips\n",
    "\n",
    "# --- Feature Parameters ---\n",
    "TARGET_SHAPE_CQCC = (128, 157)\n",
    "TARGET_SHAPE_LLD = (23, 157) # eGeMAPS LLDs have 23 features\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 5.0\n",
    "\n",
    "# --- 2. HELPER FUNCTIONS ---\n",
    "\n",
    "def extract_cqcc(y, sr, n_bins=90, n_cqcc=128):\n",
    "    \"\"\"Extracts CQCC features.\"\"\"\n",
    "    try:\n",
    "        cqt = np.abs(librosa.cqt(y=y, sr=sr, n_bins=n_bins, fmin=librosa.note_to_hz('C1')))\n",
    "        log_cqt = np.log(cqt + 1e-6)\n",
    "        cqcc = dct(log_cqt, type=2, axis=0, norm='ortho')\n",
    "        return cqcc[:n_cqcc, :]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def pad_or_truncate(array, target_shape):\n",
    "    \"\"\"Pads or truncates a 2D array to a target shape.\"\"\"\n",
    "    padded_array = np.full(target_shape, 0.0, dtype=np.float32) # Pad with 0\n",
    "    copy_shape = tuple(min(c, t) for c, t in zip(array.shape, target_shape))\n",
    "    padded_array[:copy_shape[0], :copy_shape[1]] = array[:copy_shape[0], :copy_shape[1]]\n",
    "    return padded_array\n",
    "\n",
    "def process_data_aligned(directories, label, smile_instance):\n",
    "    \"\"\"\n",
    "    Extracts aligned CQCC and eGeMAPS LLD features.\n",
    "    \"\"\"\n",
    "    cqcc_list, lld_list, labels_list = [], [], []\n",
    "\n",
    "    for directory in directories:\n",
    "        full_dir_path = os.path.join(TEAMMATE_DATA_PATH, directory)\n",
    "        print(f\"\\nProcessing directory: {full_dir_path}\")\n",
    "        if not os.path.isdir(full_dir_path):\n",
    "            continue\n",
    "\n",
    "        files = [f for f in os.listdir(full_dir_path) if f.endswith(('.flac', '.wav'))]\n",
    "        for filename in tqdm(files, desc=f\"Extracting from {directory}\"):\n",
    "            filepath = os.path.join(full_dir_path, filename)\n",
    "            try:\n",
    "                # 1. Load the 5-second audio clip once\n",
    "                audio_5s, sr = librosa.load(filepath, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "                # 2. Extract CQCC from the 5s clip\n",
    "                cqcc_feats = extract_cqcc(audio_5s, sr, n_cqcc=TARGET_SHAPE_CQCC[0])\n",
    "                if cqcc_feats is None: continue\n",
    "\n",
    "                # 3. Extract LLDs from the same 5s clip\n",
    "                # We need to save the clip to a temporary file for openSMILE to process\n",
    "                sf.write(TEMP_AUDIO_PATH, audio_5s, sr)\n",
    "                lld_df = smile_instance.process_file(TEMP_AUDIO_PATH)\n",
    "                lld_feats = lld_df.values.T # Transpose to get (features, time)\n",
    "\n",
    "                # 4. Pad both feature sets to the target shape\n",
    "                padded_cqcc = pad_or_truncate(cqcc_feats, TARGET_SHAPE_CQCC)\n",
    "                padded_lld = pad_or_truncate(lld_feats, TARGET_SHAPE_LLD)\n",
    "\n",
    "                # 5. Append to lists\n",
    "                cqcc_list.append(padded_cqcc)\n",
    "                lld_list.append(padded_lld)\n",
    "                labels_list.append(label)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError processing {filepath}: {e}\")\n",
    "\n",
    "    # Clean up the temporary audio file\n",
    "    if os.path.exists(TEMP_AUDIO_PATH):\n",
    "        os.remove(TEMP_AUDIO_PATH)\n",
    "\n",
    "    return np.array(cqcc_list), np.array(lld_list), np.array(labels_list)\n",
    "\n",
    "\n",
    "# --- 3. MAIN EXECUTION SCRIPT ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Initialize openSMILE for LLDs ---\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPS,\n",
    "        feature_level=opensmile.FeatureLevel.LowLevelDescriptors, # Use the full name, # Set to LLD\n",
    "    )\n",
    "\n",
    "    # --- Process Training Data ---\n",
    "    print(\"--- Processing Training Set ---\")\n",
    "    cqcc_bf_train, lld_bf_train, labels_bf_train = process_data_aligned(['bonafide_audio_train', 'augmented_bonafide'], 1, smile)\n",
    "    cqcc_spf_train, lld_spf_train, labels_spf_train = process_data_aligned(['spoof_audio_train'], 0, smile)\n",
    "\n",
    "    # --- Process Validation Data ---\n",
    "    print(\"\\n--- Processing Validation Set ---\")\n",
    "    cqcc_bf_val, lld_bf_val, labels_bf_val = process_data_aligned(['bonafide_audio_val'], 1, smile)\n",
    "    cqcc_spf_val, lld_spf_val, labels_spf_val = process_data_aligned(['spoof_audio_val'], 0, smile)\n",
    "\n",
    "    # --- Combine and Save Training Data ---\n",
    "    X_cqcc_train = np.concatenate((cqcc_bf_train, cqcc_spf_train), axis=0)\n",
    "    X_lld_train = np.concatenate((lld_bf_train, lld_spf_train), axis=0)\n",
    "    y_train = np.concatenate((labels_bf_train, labels_spf_train), axis=0)\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"cqcc_features_train.npy\"), X_cqcc_train)\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"egmaps_lld_features_train.npy\"), X_lld_train)\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"labels_train.npy\"), y_train)\n",
    "    print(f\"\\n✅ Training data saved. Shapes: CQCC={X_cqcc_train.shape}, LLD={X_lld_train.shape}\")\n",
    "\n",
    "    # --- Combine and Save Validation Data ---\n",
    "    X_cqcc_val = np.concatenate((cqcc_bf_val, cqcc_spf_val), axis=0)\n",
    "    X_lld_val = np.concatenate((lld_bf_val, lld_spf_val), axis=0)\n",
    "    y_val = np.concatenate((labels_bf_val, labels_spf_val), axis=0)\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"cqcc_features_val.npy\"), X_cqcc_val)\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"egmaps_lld_features_val.npy\"), X_lld_val)\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"labels_dev.npy\"), y_val)\n",
    "    print(f\"✅ Validation data saved. Shapes: CQCC={X_cqcc_val.shape}, LLD={X_lld_val.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
