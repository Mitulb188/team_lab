{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1433ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading and preprocessing static features...\n",
      "Input size for FFNN: 6 features\n",
      "\n",
      "Starting training with early stopping...\n",
      "Epoch [1/50], Batch [100/397], Train Loss: 0.3824\n",
      "Epoch [1/50], Batch [200/397], Train Loss: 0.3709\n",
      "Epoch [1/50], Batch [300/397], Train Loss: 0.3164\n",
      "Epoch [1/50] | Train Loss: 0.3286 | Val Loss: 0.2937 | Val Acc: 0.8978 | Val EER: 0.3043 | Val ROC AUC: 0.7561\n",
      "--- Improved validation loss. Saving model from epoch 1. ---\n",
      "Epoch [2/50], Batch [100/397], Train Loss: 0.1794\n",
      "Epoch [2/50], Batch [200/397], Train Loss: 0.2604\n",
      "Epoch [2/50], Batch [300/397], Train Loss: 0.2522\n",
      "Epoch [2/50] | Train Loss: 0.2568 | Val Loss: 0.2893 | Val Acc: 0.8969 | Val EER: 0.2926 | Val ROC AUC: 0.7730\n",
      "--- Improved validation loss. Saving model from epoch 2. ---\n",
      "Epoch [3/50], Batch [100/397], Train Loss: 0.3752\n",
      "Epoch [3/50], Batch [200/397], Train Loss: 0.2470\n",
      "Epoch [3/50], Batch [300/397], Train Loss: 0.2336\n",
      "Epoch [3/50] | Train Loss: 0.2531 | Val Loss: 0.2883 | Val Acc: 0.8983 | Val EER: 0.2955 | Val ROC AUC: 0.7732\n",
      "--- Improved validation loss. Saving model from epoch 3. ---\n",
      "Epoch [4/50], Batch [100/397], Train Loss: 0.2958\n",
      "Epoch [4/50], Batch [200/397], Train Loss: 0.1999\n",
      "Epoch [4/50], Batch [300/397], Train Loss: 0.2103\n",
      "Epoch [4/50] | Train Loss: 0.2514 | Val Loss: 0.2882 | Val Acc: 0.8962 | Val EER: 0.2897 | Val ROC AUC: 0.7779\n",
      "--- Improved validation loss. Saving model from epoch 4. ---\n",
      "Epoch [5/50], Batch [100/397], Train Loss: 0.2680\n",
      "Epoch [5/50], Batch [200/397], Train Loss: 0.1863\n",
      "Epoch [5/50], Batch [300/397], Train Loss: 0.2871\n",
      "Epoch [5/50] | Train Loss: 0.2509 | Val Loss: 0.2874 | Val Acc: 0.8972 | Val EER: 0.2885 | Val ROC AUC: 0.7790\n",
      "--- Improved validation loss. Saving model from epoch 5. ---\n",
      "Epoch [6/50], Batch [100/397], Train Loss: 0.1996\n",
      "Epoch [6/50], Batch [200/397], Train Loss: 0.2810\n",
      "Epoch [6/50], Batch [300/397], Train Loss: 0.2770\n",
      "Epoch [6/50] | Train Loss: 0.2498 | Val Loss: 0.2881 | Val Acc: 0.8962 | Val EER: 0.2887 | Val ROC AUC: 0.7777\n",
      "--- No improvement for 1/5 epochs. ---\n",
      "Epoch [7/50], Batch [100/397], Train Loss: 0.2822\n",
      "Epoch [7/50], Batch [200/397], Train Loss: 0.2179\n",
      "Epoch [7/50], Batch [300/397], Train Loss: 0.1424\n",
      "Epoch [7/50] | Train Loss: 0.2492 | Val Loss: 0.2863 | Val Acc: 0.8981 | Val EER: 0.2893 | Val ROC AUC: 0.7801\n",
      "--- Improved validation loss. Saving model from epoch 7. ---\n",
      "Epoch [8/50], Batch [100/397], Train Loss: 0.2846\n",
      "Epoch [8/50], Batch [200/397], Train Loss: 0.2851\n",
      "Epoch [8/50], Batch [300/397], Train Loss: 0.1529\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define paths to the data files\n",
    "# Make sure these paths are correct for your system\n",
    "TRAIN_DATA_PATH = \"/mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/student_directories/AuFa/prosodic_features_train.csv\"\n",
    "DEV_DATA_PATH = \"/mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/student_directories/AuFa/prosodic_features_dev.csv\"\n",
    "\n",
    "# Define the feature columns to use (these are already static in your CSV)\n",
    "FEATURE_COLS = ['mean_f0', 'std_f0', 'jitter', 'shimmer', 'mean_hnr', 'std_hnr']\n",
    "\n",
    "# Define hyperparameters for the simple model\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50 # Increased epochs for early stopping to have more room\n",
    "HIDDEN_SIZE = 64 # A single hidden layer size for the FFNN\n",
    "EARLY_STOPPING_PATIENCE = 5 # Number of epochs to wait for improvement before stopping\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class StaticFeatureDataset(Dataset):\n",
    "    def __init__(self, csv_file, feature_cols=FEATURE_COLS, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file with static audio features.\n",
    "            feature_cols (list): List of feature column names to use.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.transform = transform\n",
    "\n",
    "        # For static features, each row is already a sample\n",
    "        self.file_ids = self.data['filename'].tolist()\n",
    "\n",
    "        # Create label mapping (assuming 'label' column exists and is 0/1 or 'bonafide'/'spoof')\n",
    "        if self.data['label'].dtype == 'object': # Check if labels are strings\n",
    "            self.labels = {file_id: 1 if label == 'bonafide' else 0\n",
    "                           for file_id, label in self.data[['filename', 'label']].values}\n",
    "        else: # Assume labels are already integers (0 or 1)\n",
    "            self.labels = {file_id: label\n",
    "                           for file_id, label in self.data[['filename', 'label']].values}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) # Number of rows is the number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        file_id = row['filename']\n",
    "        \n",
    "        features = row[self.feature_cols].values.astype(np.float32) # Ensure float32 for PyTorch\n",
    "\n",
    "        # Handle any potential NaN values in features\n",
    "        # StandardScaler expects non-NaN values, so it's good to handle them before transformation.\n",
    "        features[np.isnan(features)] = 0.0 # Simple imputation; consider mean/median imputation if NaNs are common\n",
    "\n",
    "        # Apply transformation if provided\n",
    "        if self.transform:\n",
    "            # StandardScaler expects a 2D array (n_samples, n_features)\n",
    "            features = self.transform(features.reshape(1, -1)).flatten()\n",
    "\n",
    "        # Convert to tensor\n",
    "        features_tensor = torch.FloatTensor(features)\n",
    "        label = self.labels[file_id]\n",
    "        label_tensor = torch.FloatTensor([label]) # Keep as float tensor for BCELoss\n",
    "\n",
    "        return features_tensor, label_tensor\n",
    "\n",
    "class SimpleFFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(SimpleFFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        predictions = self.sigmoid(x)\n",
    "        return predictions\n",
    "\n",
    "def calculate_eer(labels, scores):\n",
    "    \"\"\"\n",
    "    Calculate the Equal Error Rate (EER) and the threshold at which it occurs.\n",
    "    Labels should be 0 for bona fide (negative) and 1 for spoof (positive).\n",
    "    Scores are the raw model outputs (probabilities).\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "    \n",
    "    # Find the threshold where FPR is approximately equal to (1 - TPR)\n",
    "    # i.e., where FAR is approximately equal to FRR\n",
    "    eer = 1.0\n",
    "    eer_threshold = 0.0\n",
    "    for i, _ in enumerate(thresholds):\n",
    "        far = fpr[i]\n",
    "        frr = 1 - tpr[i]\n",
    "        if far >= frr:\n",
    "            eer = (far + frr) / 2\n",
    "            eer_threshold = thresholds[i]\n",
    "            break\n",
    "    return eer, eer_threshold\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, patience):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping and record metrics per epoch.\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_eers = []\n",
    "    val_roc_aucs = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    print(\"\\nStarting training with early stopping...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0: # Print less frequently for cleaner output\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}')\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_scores = [] # Store raw scores for EER and ROC AUC\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = (outputs > 0.5).float() # Binary predictions\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_scores.extend(outputs.cpu().numpy()) # Raw probabilities/scores\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        val_eer, _ = calculate_eer(all_labels, all_scores)\n",
    "        val_eers.append(val_eer)\n",
    "\n",
    "        val_roc_auc = roc_auc_score(all_labels, all_scores)\n",
    "        val_roc_aucs.append(val_roc_auc)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f} | Val EER: {val_eer:.4f} | Val ROC AUC: {val_roc_auc:.4f}')\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_epoch = epoch + 1 # Store the epoch number\n",
    "            # Save the best model state\n",
    "            torch.save(model.state_dict(), 'best_simple_ffnn_static_spoofing_detector.pth')\n",
    "            print(f\"--- Improved validation loss. Saving model from epoch {best_epoch}. ---\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"--- No improvement for {epochs_no_improve}/{patience} epochs. ---\")\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}!\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nTraining finished. Best model saved from epoch {best_epoch} with Validation Loss: {best_val_loss:.4f}\")\n",
    "    return train_losses, val_losses, val_accuracies, val_eers, val_roc_aucs\n",
    "\n",
    "def evaluate_model(model, test_loader, device, model_path=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set, optionally loading a saved model.\n",
    "    \"\"\"\n",
    "    if model_path:\n",
    "        print(f\"Loading best model from {model_path} for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_scores = [] # Store raw scores for EER and ROC AUC\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features = features.to(device)\n",
    "\n",
    "            outputs = model(features)\n",
    "            preds = (outputs > 0.5).float() # Binary predictions\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_scores.extend(outputs.cpu().numpy()) # Raw probabilities/scores\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_scores)\n",
    "    eer, eer_threshold = calculate_eer(all_labels, all_scores)\n",
    "\n",
    "    print(\"\\n===== Model Evaluation Results =====\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Equal Error Rate (EER): {eer:.4f}\")\n",
    "    print(f\"EER Threshold: {eer_threshold:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    return accuracy, precision, recall, f1, eer, eer_threshold, roc_auc, conf_matrix\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, val_accuracies, val_eers, val_roc_aucs, num_epochs_ran, filename='simple_ffnn_static_features_metrics.png'):\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics over epochs.\n",
    "    \"\"\"\n",
    "    epochs = range(1, num_epochs_ran + 1) # Adjust epochs range for early stopping\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot EER\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, val_eers, label='Validation EER', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('EER')\n",
    "    plt.title('Validation Equal Error Rate (EER)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axhline(y=min(val_eers), color='gray', linestyle='--', label=f'Min EER: {min(val_eers):.4f}')\n",
    "\n",
    "\n",
    "    # Plot ROC AUC\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(epochs, val_roc_aucs, label='Validation ROC AUC', color='purple')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.title('Validation ROC AUC')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    print(\"Loading and preprocessing static features...\")\n",
    "    train_data_for_scaler = pd.read_csv(TRAIN_DATA_PATH)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_data_for_scaler[FEATURE_COLS].values)\n",
    "\n",
    "    transform = lambda x: scaler.transform(x)\n",
    "\n",
    "    train_dataset = StaticFeatureDataset(TRAIN_DATA_PATH, transform=transform)\n",
    "    val_dataset = StaticFeatureDataset(DEV_DATA_PATH, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    input_size = len(FEATURE_COLS)\n",
    "    print(f\"Input size for FFNN: {input_size} features\")\n",
    "\n",
    "    model = SimpleFFNN(\n",
    "        input_size=input_size,\n",
    "        hidden_size=HIDDEN_SIZE\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    train_losses, val_losses, val_accuracies, val_eers, val_roc_aucs = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        NUM_EPOCHS,\n",
    "        DEVICE,\n",
    "        EARLY_STOPPING_PATIENCE\n",
    "    )\n",
    "    \n",
    "    # Get the number of epochs actually run (due to early stopping)\n",
    "    num_epochs_ran = len(val_losses)\n",
    "\n",
    "    # Plot results after training\n",
    "    plot_metrics(train_losses, val_losses, val_accuracies, val_eers, val_roc_aucs, num_epochs_ran)\n",
    "\n",
    "    # Evaluate the model on the validation set (which now acts as our 'test' set as per your request)\n",
    "    # We load the best saved model for final evaluation.\n",
    "    print(\"\\nFinal Evaluation on the Validation Set (using best saved model):\")\n",
    "    accuracy, precision, recall, f1, eer, eer_threshold, roc_auc, conf_matrix = evaluate_model(\n",
    "        model, val_loader, DEVICE, model_path='best_simple_ffnn_static_spoofing_detector.pth'\n",
    "    )\n",
    "\n",
    "    # You can also save the final model state (the one at the last epoch run) if you wish\n",
    "    # torch.save(model.state_dict(), 'simple_ffnn_static_spoofing_detector_final_epoch.pth')\n",
    "    # print(\"Model state at last epoch saved to simple_ffnn_static_spoofing_detector_final_epoch.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
